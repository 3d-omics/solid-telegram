# Data preparation

## Sample metadata
Import sample metadata from the airtable.
```{r sample_metadata, message=FALSE, eval=FALSE}
sample_metadata <- airtable("4-MSE-Info", "appKakM1bnKSekwuW") %>% # get base ID from Airtable browser URL
  read_airtable(., fields = c("ID", "LabBatch_text", "IntestinalSection", "SampleType", 
                              "Xcoord", "Ycoord", "SizeApprox", "cryosection_text", "buffer_text", 
                              "Collection_Success", "Collection_attempts", "UsedCycles", "animal_temp", "Protocol_text",
                              "Collection_method_text" 
                              ), id_to_col = TRUE) %>%
  filter(LabBatch_text %in% c("MSEB0006", "MSEB0009", "MSEB0010", "MSEB0011", "MSEB0012", "MSEB0014", "MSEB0015")) %>%
  rename(batch = LabBatch_text, microsample = ID, section = IntestinalSection, type = SampleType, 
         cryosection = cryosection_text, buffer = buffer_text, collection = Collection_Success, collection_attempts = Collection_attempts, 
         cycles = UsedCycles, animal = animal_temp, size = SizeApprox, protocol = Protocol_text, collection_method = Collection_method_text) %>%
  select(microsample, section, type, batch, 
         cryosection, buffer, Xcoord, Ycoord, 
         size, collection, collection_attempts, 
         cycles, animal, protocol, collection_method) %>%
  unnest(c(section, Xcoord, Ycoord, size, collection, cycles, collection_method)) %>%
  arrange(microsample)

print(names(sample_metadata))

```

## Count data
```{r load_count, message=FALSE, eval=FALSE, warning=FALSE, comments=""}
read_counts <- read_tsv("data/MSEB0006_read_counts.tsv", show_col_types = FALSE) %>%
  left_join(read_tsv("data/MSEB0009_read_counts.tsv", show_col_types = FALSE), by = "sequence_id") %>%
  left_join(read_tsv("data/MSEB0010_read_counts.tsv", show_col_types = FALSE), by = "sequence_id") %>%
  left_join(read_tsv("data/MSEB0011_read_counts.tsv", show_col_types = FALSE), by = "sequence_id") %>%
  left_join(read_tsv("data/MSEB0012_read_counts.tsv", show_col_types = FALSE), by = "sequence_id") %>%
  left_join(read_tsv("data/MSEB0014_read_counts.tsv", show_col_types = FALSE), by = "sequence_id") %>%
  left_join(read_tsv("data/MSEB0015_read_counts.tsv", show_col_types = FALSE), by = "sequence_id") %>%
  rename(genome = 1) %>%
  pivot_longer(!genome, names_to = "data", values_to = "counts") %>%
  mutate(sample = substr(data, 1, 7)) %>%
  group_by(genome, sample) %>%
  summarise(counts = sum(counts), .groups = "drop") %>%
  pivot_wider(names_from = "sample", values_from = "counts")
```

### Base hit table
This is the document containing the number of nucleotide bases have been covered by at least one read in each sample and MAG. This information is used to calculate MAG coverage values.

```{r load_hits, message=FALSE, eval=FALSE}
basehits <- read_tsv("data/MSEB0006_covered_bases.tsv", show_col_types = FALSE) %>%
  left_join(read_tsv("data/MSEB0009_covered_bases.tsv", show_col_types = FALSE), by = "sequence_id") %>%
  left_join(read_tsv("data/MSEB0010_covered_bases.tsv", show_col_types = FALSE), by = "sequence_id") %>%
  left_join(read_tsv("data/MSEB0011_covered_bases.tsv", show_col_types = FALSE), by = "sequence_id") %>%
  left_join(read_tsv("data/MSEB0012_covered_bases.tsv", show_col_types = FALSE), by = "sequence_id") %>%
  left_join(read_tsv("data/MSEB0014_covered_bases.tsv", show_col_types = FALSE), by = "sequence_id") %>%
  left_join(read_tsv("data/MSEB0015_covered_bases.tsv", show_col_types = FALSE), by = "sequence_id") %>%
  rename(genome = 1) %>%
  pivot_longer(!genome, names_to = "data", values_to = "counts") %>%
  mutate(sample = substr(data, 1, 7)) %>%
  group_by(genome, sample) %>%
  summarise(counts = sum(counts), .groups = "drop") %>%
  pivot_wider(names_from = "sample", values_from = "counts")
```

### Genome metadata
Relevant metadata of genomes is fetched from 2-3 files and merged into one genome metadata object for downstream analyses.

#### Taxonomy
This is the raw taxonomy table generated by GTDBtk, which is simplified for downstream analyses.
```{r load_taxonomy, message=FALSE, eval=FALSE}
genome_taxonomy <- read_tsv("data/genome_taxonomy.tsv", show_col_types = FALSE) %>%
  rename(genome = user_genome) %>%
  mutate(genome = str_replace_all(genome, "\\.fa", "")) %>%
  separate(classification, c("domain", "phylum", "class", "order", "family", "genus", "species"), sep = ";") %>%
  select(genome, domain, phylum, class, order, family, genus, species) %>%
  arrange(match(genome, read_counts$genome))
```

#### Genome quality
Quality properties of the genomes. 
```{r load_quality, message=FALSE, eval=FALSE}
genome_quality <- read_tsv("data/genome_quality.tsv", show_col_types = FALSE) %>%
  rename(genome = 1) %>%
  mutate(genome = str_replace_all(genome, "\\.fa", "")) %>%
  arrange(match(genome, read_counts$genome)) %>%
  select(genome, Completeness, Contamination, Coding_Density, Genome_Size) %>%
  rename(completeness = Completeness, contamination = Contamination, coding_density = Coding_Density, length = Genome_Size)
```

#### Merged metadata object
Merge taxonomy, length and quality information
```{r create_genomemetadata, message=FALSE, eval=FALSE}
genome_metadata <- genome_taxonomy %>%
  left_join(genome_quality, by = join_by(genome == genome)) # join quality
```

### Genome tree
This is the raw tree generated by GTDBtk, which needs to be pruned to obtain the phylogenetic tree of the genomes. Note that the archaeal tree is only generated if any archaeans are detected among the genomes.
```{r load_tree, message=FALSE, warning=FALSE, eval=FALSE}
genome_tree <- read.tree("data/genome_tree.tre")
genome_tree$tip.label <- str_replace_all(genome_tree$tip.label, "'", "") # remove single quotes in MAG names
genome_tree <- keep.tip(genome_tree, tip = read_counts$genome) # keep only MAG tips
```

### MAG functional annotations
This is the raw annotation table generated by DRAM, which is used to generate GIFT data using distillR.
```{r load_annotations, message=FALSE, eval=FALSE}
genome_annotations <- read_tsv("data/genome_annotations.tsv.xz", show_col_types = FALSE) %>%
  rename(gene = 1, genome = 2)
```

## Filter and normalise data
Raw data needs to be filtered and normalised to make it useful for downstream analyses. 

### Generate coverage table
By dividing the number of base hits by the length of each genome, coverage values can be calculated.
```{r calc_coverage, eval=FALSE}
genome_coverage <- basehits %>%
  mutate(across(where(is.numeric), ~ . / genome_metadata$length))
```

### Coverage filtering
Genomes that have less than 30% of their length covered by reads are turned into zeros to account for the random allocation of reads across genomes due to mapping heuristics. 
```{r filter_coverage, eval=FALSE}
min_coverage <- 0.3
read_counts_filt <- genome_coverage %>%
  mutate(across(where(is.numeric), ~ ifelse(. > min_coverage, 1, 0))) %>%
  mutate(across(-1, ~ . * read_counts[[cur_column()]]))
```

### Generate genome count table
After filtering the low-coverage reads, read counts are transformed into genome counts using genome-length and read-length information.
```{r calc_genometable, eval=FALSE}
readlength <- 150 # change if sequencing read length is different
genome_counts_filt <- read_counts_filt %>%
  mutate(across(where(is.numeric), ~ . / (genome_metadata$length / readlength)))

genome_counts <- read_counts %>%
  mutate(across(where(is.numeric), ~ . / (genome_metadata$length / readlength)))
```

### Distil functional annotations
Raw functional annotations are distilled into genome-inferred functional traits to generate biologically more meaningful functional traits for downstream analyses.

```{r distill_annotations, warning=FALSE, comments="", message=FALSE, results='hide', eval=FALSE}
genome_gifts <- distill(genome_annotations, GIFT_db, genomecol = 2, annotcol = c(9, 10, 19))
```

## Color scheme

[AlberdiLab](www.alberdilab.dk) projects use unified color schemes developed for the [Earth Hologenome Initiative](www.earthhologenome.org), to facilitate figure interpretation.

```{r get_ehi_colors, warning=FALSE, comments="", message=FALSE, eval=FALSE}
phylum_colors <- read_tsv("https://raw.githubusercontent.com/earthhologenome/EHI_taxonomy_colour/main/ehi_phylum_colors.tsv", show_col_types = FALSE) %>%
  right_join(genome_metadata, by = join_by(phylum == phylum)) %>%
  arrange(match(genome, genome_tree$tip.label)) %>%
  select(phylum, colors) %>%
  unique() %>%
  arrange(phylum) %>%
  pull(colors, name = phylum)
```

## Wrap working objects
In the last step, the objects that are needed for downstream analyses are stored in an R object.

```{r wrap_objects, eval=FALSE}
save(read_counts,
  read_counts_filt,
  genome_counts,
  genome_counts_filt,
  genome_tree,
  genome_metadata,
  genome_gifts,
  sample_metadata,
  phylum_colors,
  file = "data/data.Rdata"
)
```

- **read_counts**: Number of reads mapped to each genome in each sample. Note this is the unfiltered and unnormalised raw community composition table.
- **genome_counts**: Number of genomes quantified in each sample, calculated through filtering and normalising ***read_counts***. This is the community composition table to be used in downstream analyses unless otherwise stated.
- **genome_tree**: Phylogenetic tree of the genomes, to be employed in downstream phylogenetic analyses.
- **genome_metadata**: Taxonomic and quality information of the genomes.
- **sample_metadata**: Treatment/population and other relevant metadata of the samples.
